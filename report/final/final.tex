
%% bare_jrnl.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/


\documentclass[journal]{IEEEtran}
\usepackage{graphicx, amsmath, amssymb, epstopdf}

% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
\usepackage{graphicx}





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.


%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley and Jeff Goldberg.
% This package may be useful when used in conjunction with IEEEtran.cls'
% captionsoff option. Some IEEE journals/societies require that submissions
% have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.3.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% For subfigure.sty:
% \let\MYorigsubfigure\subfigure
% \renewcommand{\subfigure}[2][\relax]{\MYorigsubfigure[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat/subfig command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/endfloat/
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a
% page by themselves.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Predicting movie ratings}


\author{Carolyn~Au~\IEEEmembership{auc@stanford.edu},
        Justin~Cunningham~\IEEEmembership{jcnnghm@stanford.edu},
        and~Weixiong~Zheng~\IEEEmembership{zhengwx@stanford.edu}}


% The paper headers
\markboth{CS 221 (Autumn 2014) Project Final Report}%
{}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.


% make the title area
\maketitle


\begin{abstract}
The project aims to explore machine learning methods to predict a movie's critical success prior
to it's release, i.e. based solely on metadata available about the movie. The code for this project
can be found at \texttt{\url{https://github.com/jcnnghm/cs221-project}}
\end{abstract}



\section{Introduction}
The movie industry generates multi-billion dollars in revenue and most movies
cost millions of dollars to create.  However, not all movies are successes.
With such high risk and large amounts of money involved, it would be useful to
be able to predict the success of a movie before it is released. In this
project, we try to predict the critical success of a movie, as shown by user
ratings on IMDb, based solely on metadata about a movie available prior to it's
release.

\subsection{Progress summary}
We have developed a framework to access and extract features from our dataset,
and have performed initial training on our extracted features.  We have improved 
upon our baseline standard error of 1.78, achieving standard errors as low as 0.79.
In addition, we have started to tune our features and have assembled a framework for
rapidly iterating on our algorithms so we can tune them.  We have also made efforts 
to prune unnecessary features.

Going forward, we need to further prune our features, as well as tune the
hyperparameters of our algorithms.  We also will be feeding the result from K-means, an unsupervised learning algorithm, into our supervised algorithms, and measuring the impact that
it is able to have on our results under a variety of conditions.

\section{Dataset}
Our dataset is the list of all movies from IMDb that fulfill the following properties
\begin{itemize}
	\item Released in the US
	\item Generated gross earnings in the US
	\item Has at least 1,000 user votes to rate the movie
\end{itemize}

\par After pruning the database of 3 million entries, we are left with 9,888
movies which is a reasonable number for our algorithms to run on. Limiting the
data to movies with a reasonable number of user votes also ensures that the
rating data is not too noisy. We save 20\% of the data for testing, and use the
rest for development.

\scalebox{0.55}{\includegraphics{ratings.eps}}

The user ratings in our dataset have a mean of 6.5 and a median of 6.6 with a standard deviation of 1.05.

\section{System design}
Our system is composed of a feature creator system, a snapshot of the IMDb dataset,
and a variety of learning algorithms that operate on the information exported by
the feature creator.
\par The feature creator provides a framework that allows sub-component
feature extractors to interact with the IMDb dataset, stored in MySQL.  The feature
creator calls each extractor ($E_i$ in the diagram below) in turn for each of the movies we've selected for our
dev and test sets, and merges their output features into a sparse feature vector for
each movie.  An additional combinator step is applied to generate feature
combinations, e.g. \{movie director $\times$ movie actors\}.
\par The creator is highly configurable so that extractors and combinators can easily be selectively enabled or disabled,
and includes a caching layer to reduce the load on MySQL and speed up processing.
The feature vectors are stored in JSON so that they can be easily
post-processed for use with different algorithms. \\

\begin{center}
    \includegraphics[width=6cm]{charts/system.png}
\end{center}

Each algorithm is responsible for transforming the data to the format that it requires.
The neural network, for example, converts the sparse vectors from the feature creator
into a dense representation that can be consumed by FANN \cite{fann}, a neural network library.  Each
component is modular, so the output of some algorithms can potentially be combined with others ($A_i$ in the diagram above).

\section{Features}
The feature creator system extracts raw features, and then combines some
features with others, like actors with directors, to form compound
"combination" features, e.g. \{movie director $\times$ movie actors\}.
Below is a detailed description of each class of features we include along with
an example of the features we generate.

\subsection{Individual features}
\subsubsection{Budget}
The Budget feature extractor extracts a weighted feature, within the domain of
\$1 to \$300M.  Since the data is crowdsourced, there are multiple specified
budgets for the movie.  We only consider movies with budgets in US dollars, and
we take the largest proposed budget.  We also consider using budgets in two
ways -- using raw dollar values or bucketing the value into \$5M chunks (as
indicator variables).

\begin{align*}
        \{ \ \ & \\
        &"budget": 10000000,\\
        &"budget\_bucket\_2: 1\\
        \} \ \ &
\end{align*}

\subsubsection{Cast}
The cast feature extractor generates indicator features for each
cast and crew member associated with a film, for each job they 
performed.  An individual could potentially appear more than once,
if they performed different jobs, for example, if they were both
an actor and director.  The cast roles which we include are:
\begin{itemize}
	\item Actor
	\item Actress
	\item Producer
	\item Writer
	\item Cinematographer
	\item Composer
	\item Costume designer
	\item Director
	\item Editor
	\item Production designer
	\item Miscellaneous crew
\end{itemize}

\begin{align*}
        \{ \ \ & \\
        &"Lasseter,John\_producer": 1,\\
        &"Cummings,Jim\_actor": 1,\\
        &"Mitchell,Nicole\_writer": 1,\\
        \} \ \ &
\end{align*}

\subsubsection{Genre}
Genre features are indicator features that are activated for each
genre associated with a movie in the IMDb dataset.

\begin{align*}
        \{\ \ &\\
        &"genre\_Family": 1,\\
        &"genre\_Comedy": 1,\\
        \}\ \ &
\end{align*}

\subsubsection{Keywords}
Keyword features are indicator features that are activated for
each searchable tag that is associated with a movie in the
IMDb dataset.

\begin{align*}
        \{\ \ &\\
        &"character-name-in-title": 1,\\
        &"sequel": 1,\\
        &"friendship": 1,\\
        \}\ \ &
\end{align*}

\subsubsection{Release Date}
Release dates are also indicator features that are activated for each release
in the US across festivals and premieres. For each release, we generate 3
features, one for the month, year, and both month and year.

\begin{align*}
        \{\ \ &\\
        &"release\ (traverse\ film\ festival)\ (August)": 1, \\
        &"release\ (traverse\ film\ festival)\ (2014)": 1, \\
        &"release\ (traverse\ film\ festival)\ (August\ 2014)": 1, \\
        &"release\ (premiere)\ (February)": 1, \\
        &"release\ (premiere)\ (2014)": 1, \\
        &"release\ (premiere)\ (February\ 2014)": 1, \\
        \}\ \ &
\end{align*}

\subsubsection{Budget $\times$ Cast}
We use the bucketized budget data and join that with the extracted cast
features. The idea is that an actor's star power will be amplified by a big
budget production, or reduced in an indie movie.

\begin{align*}
        \{\ \ &\\
        &"budget\_bucket\_2\_Cummings,Jim\_actor": 1,\\
        &"budget\_bucket\_2\_Klein,Sebastian\_actor": 1\\
        \}\ \ &
\end{align*}

\subsubsection{Actor $\times$ Director}
We create new features for each combination of actor and director in each cast
list (where actor includes both actors and actresses, treated distinctly in our
dataset). The intuition is that some pairs of actors and directors work well
together and create better movies together.

\begin{align*}
        \{\ \ &\\
        &"Nolan,Christopher\_Cummings,Jim\_actor": 1,\\
        &"Nolan,Christopher\_Klein,Sebastian\_actor": 1\\
        \}\ \ &
\end{align*}

\subsection{Preliminary analysis of feature sets}
In total, there are about 192,000 unique features without combined features for
our data set.  With combined features, this number balloons to over 800,000.

\scalebox{0.55}{\includegraphics{charts/features_without_cross_chart.eps}}

\scalebox{0.55}{\includegraphics{charts/features_with_cross_chart.eps}}

When represented sparsely, the feature size without combinations is about 53MB, and 82MB with combinations.  The same data represented
densely consumes approximately 3.5GB and 14GB respectively, indicating that many of the features are not associated with many movies.  Features are associated with an average of 8 movies, skewed heavily to the left. \\
\\
\scalebox{0.50}{\includegraphics{charts/movies_per_feature.eps}}
\\
\par An initial investigation into the importance of each feature was performed by
running our baseline algorithm with each feature set individually.\\
\\
\begin{tabular}{|l|r r|} % columns
\hline
Feature & Std error on Dev & Std Error on Test \\ [0.5ex] % inserts table 
\hline % inserts single horizontal line
Budget (raw) & 5.89 & 5.87 \\ % inserting body of the table
Budget (bucketized) & 4.62 & 4.68 \\
Cast & 0.65 & 2.56 \\
Genre & 2.26 & 2.29 \\
Keywords & 1.65 & 3.35 \\
Release date & 1.69 & 2.26 \\
Budget $\times$ Cast & 4.54 & 5.65 \\
Actor $\times$ Director & 2.67 & 5.96 \\
\hline
\end{tabular}
\smallskip
\par Here we note that some feature sets are overfitted to our dev dataset such as
cast, keywords, release date, budget $\times$ cast and actor $\times$ director.
These are also our largest feature sets.\\
\\
\begin{tabular}{|l| r r r|} % columns
\hline
Feature             & \shortstack[c]{Num.\\vars} & \shortstack[c]{Num.\\movies} & \shortstack[c]{Feature / \\ movie}  \\ [0.5ex] % inserts table 
\hline
Budget (raw)        & N/A & 5,278 (53\%) & 1 \\ % inserting body of the table
Budget (bucketized) & 52 & 5,278 (53\%) & 1 \\
Cast                & 169,973 & 9,883 (99\%) & 72 \\
Genre               & 25 & 9,885 (99\%) & 2 \\
Keywords            & 11,701 & 9,774 (98\%) & 75 \\
Release date        & 10,500 & 9,884 (99\%) & 7 \\
Budget $\times$ Cast & 394,661 & 5,278 (53\%) & 92 \\
Actor $\times$ Director & 282,672 & 8,630 (87\%) & 35 \\
\hline %inserts single line
\end{tabular}

\subsection{Feature pruning}
With combined features, our feature space size is around 800,000. It takes hours to train a Linear Regression Model using scikit-learn \cite{scikit} on such a large sample space. We did some experiments on feature removal to improve algorithm performance.
\par In our experiments, we removed all the features that appear less or equal to $n$ times in the training data before training a model. We measured the number of features left after removal, time spent to train Linear Regression using scikit-learn and the standard error on test set.\\
\\
\begin{tabular}{|l| r r r|} % columns
\hline
$n$ & Num. features left & Running time & Standard Error  \\ [0.5ex] % inserts table 
\hline
0 & 723,000 & $>$ 10 Hours & N/A \\
1 & 188,000 & 2.44 Hours & 0.79 \\
2 & 93,000 & 2.34 Hours & 0.83 \\
9 & 28,000 & 2.07 Hours & 1.12 \\ [1ex]
\hline %inserts single line
\end{tabular}
\smallskip
\\
\par Removing the features that
appear only once in the training set gives huge improvements on performance
while maintaining low standard errors on fitting the test set. This makes sense
because if a
feature appears only once in the training set, it's highly likely that the
feature won't appear in the test set, which means that the weight for this feature
won't affect the result of fitting the test set. Also, according to the experiment,
increasing the threshold $n$ doesn't give too much performance gain but worsens
the test error.

\section{Learning algorithms}
We tried three machine learning models: Neural Network, Linear Regression, and
Support Vector Machines (SVM).

\subsection{Implemented algorithms}
\subsubsection{Neural Network}
The neural network is implemented using the Fast Artificial Neural Network (FANN)
API.  With two hidden layers, with 20 neurons in the first and 10 in the second, 
we have achieved a test error rate of 0.012, when the rating is represented as a
number between 0 and 1.0, corresponding to an average error of approximately 1.1 out of 10.  

The neural network is slow to learn, so we plan to reduce the number of features so we can
iterate more quickly.  In addition, we plan to tune the network topology once we're able
to achieve acceptable iteration speeds.

\subsubsection{Linear Regression}
We used the implementation of Linear Regression in scikit-learn with default
parameters. We used feature removal threshold 1. The algorithm took 2.4 hours
to run and gave standard error 0.79.

\subsubsection{SVM}
We used the implementation of SVM in scikit-learn with radial basis function (rbf) kernel and linear kernel. We used the feature removal threshold of 1. SVM with rbf kernel took 3.3 hours to run and gave standard error of 1.09. SVM with linear kernel took 3 minutes to run and gave standard error of 1.02.

\subsection{Preliminary analysis}
\smallskip
\begin{tabular}{|l |l l|} % columns
\hline
Model               & Time to fit & Standard Error  \\ [0.5ex] % inserts table 
\hline
Neural network      & $>$ 10 hours  & 1.1 \\
Linear regression   & 2.4 hours   & 0.79 \\
SVM (rbf kernel)    & 3.3 hours   & 1.09 \\
SVM (linear kernel) & 3 minutes   & 1.02 \\ [1ex]
\hline %inserts single line
\end{tabular}
\smallskip
\\
\par The best model we have so far is Linear Regression which gives 0.79 test error.
Compare this to our baseline test error of 1.78 and oracle test error of 0.34.
We believe the improvement is mostly from feature tuning.

\section{Next steps}
To get better models and improve the prediction accuracy, we plan to further improve both our feature set and the algorithms.

\subsection{Combined Features}
We already have some combined features such as Budget $\times$ Cast and Actor $\times$ Director. We plan to experiment with more combined features, e.g. Actor $\times$ Actor, Director $\times$ Genre, etc.

\subsection{Derived Features}
We plan to experiment on a few derived features. For example, we think the experience of the director, actor, or screenwriter might have considerable impact on the rating of a movie. However, none of the features we have right now capture the experience of the film crew. We plan to do some analysis on the training data. On each movie, we will count the number of movies the cast member has made before making this movie and add the counts as new weighted feature. We will also derive more features from them, e.g. average experience of crew member, average experience of actors, etc.

\subsection{Model \& Algorithm}
We plan to focus on improving the Neural Network model. We will first try to decrease the runtime of training the Neural Network model to an acceptable range so we can quickly iterate. To achieve this, we will try a few techniques such as feature removal or PCA. After that, we will work on improving the Neural Network model to achieve better prediction accuracy by tuning the topology of the Neural Network. We also plan to apply k-means to categorize the training data, generating a set of clusters for the dataset, then treating each cluster as an indicator feature to feed into later algorithms.

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}
\bibitem{fann}
Fast Artificial Neural Network Library: \texttt{\url{http://leenissen.dk/fann/wp/}}
\bibitem{scikit}
Scikit-learn: \texttt{\url{http://scikit-learn.org/stable/}}
\end{thebibliography}


% that's all folks
\end{document}


